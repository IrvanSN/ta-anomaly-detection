{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "roVG32PxU7Xf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from google.colab import drive\n",
        "import datetime\n",
        "import math\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define headers for the dataset\n",
        "header = [\n",
        "    \"timestamp\",\n",
        "    \"cpu_usage\",\n",
        "    \"top_1_cpu_proc_name\",\n",
        "    \"top_1_cpu_proc_usage\",\n",
        "    \"top_2_cpu_proc_name\",\n",
        "    \"top_2_cpu_proc_usage\",\n",
        "    \"top_3_cpu_proc_name\",\n",
        "    \"top_3_cpu_proc_usage\",\n",
        "    \"top_4_cpu_proc_name\",\n",
        "    \"top_4_cpu_proc_usage\",\n",
        "    \"top_5_cpu_proc_name\",\n",
        "    \"top_5_cpu_proc_usage\",\n",
        "    \"mem_usage\",\n",
        "    \"top_1_mem_proc_name\",\n",
        "    \"top_1_mem_proc_usage\",\n",
        "    \"top_2_mem_proc_name\",\n",
        "    \"top_2_mem_proc_usage\",\n",
        "    \"top_3_mem_proc_name\",\n",
        "    \"top_3_mem_proc_usage\",\n",
        "    \"top_4_mem_proc_name\",\n",
        "    \"top_4_mem_proc_usage\",\n",
        "    \"top_5_mem_proc_name\",\n",
        "    \"top_5_mem_proc_usage\",\n",
        "    \"nginx_active_connections\",\n",
        "    \"nginx_rps\"\n",
        "]\n",
        "\n",
        "# Load the dataset with semicolon delimiter\n",
        "df = pd.read_csv(\n",
        "    \"drive/MyDrive/Colab Notebooks/dataset/system_stats.csv\",\n",
        "    header=None,\n",
        "    names=header,\n",
        "    sep=';',\n",
        "    low_memory=False,\n",
        "    on_bad_lines='skip'\n",
        ")\n",
        "\n",
        "# Display basic information\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "df.head()\n",
        "\n",
        "# Handle timestamp parsing\n",
        "# First, clean up any extra characters that might interfere with parsing\n",
        "df['timestamp'] = df['timestamp'].str.replace('T', ' ')\n",
        "df['timestamp'] = df['timestamp'].str.split('.').str[0]\n",
        "\n",
        "# Now try to parse timestamps\n",
        "try:\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
        "except:\n",
        "    print(\"Warning: Some timestamp parsing failed, using a more flexible approach\")\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
        "\n",
        "# Drop rows with invalid timestamps\n",
        "df = df.dropna(subset=['timestamp'])\n",
        "print(f\"Dataset shape after cleaning timestamps: {df.shape}\")\n",
        "\n",
        "# Extract time features\n",
        "df['hour'] = df['timestamp'].dt.hour\n",
        "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "df['day_of_month'] = df['timestamp'].dt.day\n",
        "\n",
        "# Check data types and convert numerical columns from strings to float\n",
        "numeric_cols = [\n",
        "    'cpu_usage', 'top_1_cpu_proc_usage', 'top_2_cpu_proc_usage',\n",
        "    'top_3_cpu_proc_usage', 'top_4_cpu_proc_usage', 'top_5_cpu_proc_usage',\n",
        "    'mem_usage', 'top_1_mem_proc_usage', 'top_2_mem_proc_usage',\n",
        "    'top_3_mem_proc_usage', 'top_4_mem_proc_usage', 'top_5_mem_proc_usage',\n",
        "    'nginx_active_connections', 'nginx_rps'\n",
        "]\n",
        "\n",
        "for col in numeric_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Select only numerical features for the autoencoder (excluding process names)\n",
        "numerical_features = [\n",
        "    'cpu_usage', 'top_1_cpu_proc_usage', 'top_2_cpu_proc_usage',\n",
        "    'top_3_cpu_proc_usage', 'top_4_cpu_proc_usage', 'top_5_cpu_proc_usage',\n",
        "    'mem_usage', 'top_1_mem_proc_usage', 'top_2_mem_proc_usage',\n",
        "    'top_3_mem_proc_usage', 'top_4_mem_proc_usage', 'top_5_mem_proc_usage',\n",
        "    'nginx_active_connections', 'nginx_rps',\n",
        "    'hour', 'day_of_week', 'day_of_month'\n",
        "]\n",
        "\n",
        "# These are the features we'll use for training\n",
        "features = numerical_features.copy()\n",
        "\n",
        "# Check for and handle missing values\n",
        "print(f\"Missing values:\\n{df[features].isna().sum()}\")\n",
        "df[features] = df[features].fillna(0)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = pd.DataFrame(scaler.fit_transform(df[features]), columns=features)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test = train_test_split(df_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the autoencoder model\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "# Define the encoder\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "# Encoder layers\n",
        "encoder = Dense(64, activation='relu')(input_layer)\n",
        "encoder = Dropout(0.2)(encoder)\n",
        "encoder = Dense(32, activation='relu')(encoder)\n",
        "encoder = Dropout(0.2)(encoder)\n",
        "\n",
        "# Bottleneck layer\n",
        "bottleneck = Dense(16, activation='relu')(encoder)\n",
        "\n",
        "# Decoder layers\n",
        "decoder = Dense(32, activation='relu')(bottleneck)\n",
        "decoder = Dropout(0.2)(decoder)\n",
        "decoder = Dense(64, activation='relu')(decoder)\n",
        "decoder = Dropout(0.2)(decoder)\n",
        "\n",
        "# Output layer\n",
        "output_layer = Dense(input_dim, activation='sigmoid')(decoder)\n",
        "\n",
        "# Create model\n",
        "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Print model summary\n",
        "autoencoder.summary()\n",
        "\n",
        "# Train the model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "history = autoencoder.fit(\n",
        "    X_train, X_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, X_test),\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Autoencoder Training History')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Get reconstruction on the entire dataset\n",
        "reconstructed = autoencoder.predict(df_scaled)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "# MAE (Mean Absolute Error)\n",
        "mae = mean_absolute_error(df_scaled, reconstructed)\n",
        "# MSE (Mean Squared Error)\n",
        "mse = mean_squared_error(df_scaled, reconstructed)\n",
        "# RMSE (Root Mean Squared Error)\n",
        "rmse = math.sqrt(mse)\n",
        "\n",
        "print(\"\\n===== Autoencoder Evaluation Metrics =====\")\n",
        "print(f\"MAE: {mae:.6f}\")\n",
        "print(f\"MSE: {mse:.6f}\")\n",
        "print(f\"RMSE: {rmse:.6f}\")\n",
        "\n",
        "# Calculate per-feature reconstruction errors for analysis\n",
        "feature_mae = np.mean(np.abs(df_scaled.values - reconstructed), axis=0)\n",
        "feature_mse = np.mean(np.square(df_scaled.values - reconstructed), axis=0)\n",
        "feature_rmse = np.sqrt(feature_mse)\n",
        "\n",
        "# Create dataframe for feature-wise metrics\n",
        "feature_metrics = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'MAE': feature_mae,\n",
        "    'MSE': feature_mse,\n",
        "    'RMSE': feature_rmse\n",
        "})\n",
        "\n",
        "# Sort by RMSE to see which features have the highest reconstruction error\n",
        "feature_metrics_sorted = feature_metrics.sort_values('RMSE', ascending=False)\n",
        "print(\"\\n===== Feature-wise Reconstruction Errors =====\")\n",
        "print(feature_metrics_sorted)\n",
        "\n",
        "# Visualize feature-wise reconstruction errors\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.bar(feature_metrics_sorted['Feature'], feature_metrics_sorted['RMSE'])\n",
        "plt.title('RMSE by Feature')\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('RMSE')\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Get reconstruction error on the entire dataset (per-sample MSE)\n",
        "sample_mse = np.mean(np.power(df_scaled - reconstructed, 2), axis=1)\n",
        "\n",
        "# Add reconstruction error to original dataframe\n",
        "df['reconstruction_error'] = sample_mse\n",
        "\n",
        "# Determine anomaly threshold (you can adjust this based on your needs)\n",
        "# Here we use mean + 2*std as threshold\n",
        "threshold = np.mean(sample_mse) + 2 * np.std(sample_mse)\n",
        "print(f\"Anomaly threshold: {threshold}\")\n",
        "\n",
        "# Flag anomalies\n",
        "df['is_anomaly'] = df['reconstruction_error'] > threshold\n",
        "anomaly_count = df['is_anomaly'].sum()\n",
        "print(f\"Number of anomalies detected: {anomaly_count} ({anomaly_count/len(df)*100:.2f}%)\")\n",
        "\n",
        "# Plot reconstruction error\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(df['timestamp'], df['reconstruction_error'], label='Reconstruction Error')\n",
        "plt.axhline(y=threshold, color='r', linestyle='-', label=f'Threshold ({threshold:.4f})')\n",
        "plt.fill_between(df['timestamp'], threshold, df['reconstruction_error'],\n",
        "                 where=(df['reconstruction_error'] > threshold), color='red', alpha=0.3)\n",
        "plt.title('Reconstruction Error Over Time')\n",
        "plt.xlabel('Timestamp')\n",
        "plt.ylabel('Reconstruction Error (MSE)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display anomalies with highest reconstruction error\n",
        "top_anomalies = df[df['is_anomaly']].sort_values('reconstruction_error', ascending=False).head(10)\n",
        "print(\"Top 10 anomalies by reconstruction error:\")\n",
        "display(top_anomalies[['timestamp', 'cpu_usage', 'mem_usage', 'nginx_rps', 'reconstruction_error']])\n",
        "\n",
        "# Feature contribution to anomalies\n",
        "if anomaly_count > 0:\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    anomaly_indices = df[df['is_anomaly']].index\n",
        "    feature_errors = np.power(df_scaled.iloc[anomaly_indices].values -\n",
        "                            reconstructed[anomaly_indices], 2)\n",
        "    feature_error_df = pd.DataFrame(feature_errors, columns=features)\n",
        "    feature_contribution = feature_error_df.mean().sort_values(ascending=False)\n",
        "\n",
        "    plt.bar(feature_contribution.index, feature_contribution.values)\n",
        "    plt.title('Feature Contribution to Anomalies')\n",
        "    plt.xlabel('Features')\n",
        "    plt.ylabel('Average Squared Error')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize normal vs anomalous data points for top contributing features\n",
        "if anomaly_count > 0:\n",
        "    top_features = feature_contribution.head(6).index\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, feature in enumerate(top_features):\n",
        "        ax = axes[i]\n",
        "        sns.histplot(data=df, x=feature, hue='is_anomaly', bins=30, ax=ax,\n",
        "                   palette={True: 'red', False: 'blue'}, alpha=0.5, legend=i==0)\n",
        "        ax.set_title(f'Distribution of {feature}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize actual vs. reconstructed values for a few features\n",
        "sample_size = min(1000, len(df))  # Limit to 1000 samples for visualization\n",
        "sample_idx = np.random.choice(len(df), sample_size, replace=False)\n",
        "\n",
        "for feature in features[:3]:  # Visualize first 3 features\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Get original and reconstructed values\n",
        "    original = df_scaled.iloc[sample_idx][feature].values\n",
        "    reconstructed_values = reconstructed[sample_idx, features.index(feature)]\n",
        "\n",
        "    # Plot scatter of original vs reconstructed\n",
        "    plt.scatter(original, reconstructed_values, alpha=0.5)\n",
        "\n",
        "    # Plot perfect reconstruction line\n",
        "    min_val = min(original.min(), reconstructed_values.min())\n",
        "    max_val = max(original.max(), reconstructed_values.max())\n",
        "    plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
        "\n",
        "    plt.title(f'Original vs Reconstructed: {feature}')\n",
        "    plt.xlabel('Original Value (Normalized)')\n",
        "    plt.ylabel('Reconstructed Value')\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Calculate error distribution\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(df['reconstruction_error'], bins=50, kde=True)\n",
        "plt.axvline(threshold, color='r', linestyle='--', label=f'Threshold ({threshold:.4f})')\n",
        "plt.title('Distribution of Reconstruction Errors')\n",
        "plt.xlabel('Reconstruction Error (MSE)')\n",
        "plt.ylabel('Count')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save the model if needed\n",
        "autoencoder.save('/content/drive/MyDrive/Colab Notebooks/system_anomaly_detector.h5')\n",
        "print(\"Model saved to Google Drive\")\n",
        "\n",
        "# Save the full results with all original features plus anomaly detection columns\n",
        "# Convert boolean to string \"True\" or \"False\" for better readability in CSV\n",
        "df['is_anomaly'] = df['is_anomaly'].astype(str)\n",
        "\n",
        "# Save all original columns plus reconstruction_error and is_anomaly\n",
        "# Remove temporary columns we added for analysis\n",
        "columns_to_drop = ['hour', 'day_of_week', 'day_of_month']\n",
        "results_df = df.drop(columns=columns_to_drop)\n",
        "\n",
        "# Save to CSV\n",
        "results_df.to_csv('/content/drive/MyDrive/Colab Notebooks/system_anomaly_full_results.csv', index=False)\n",
        "print(\"Full results with original features and anomaly flags saved to Google Drive\")\n",
        "\n",
        "# Also save a focused version with just the anomalies\n",
        "anomaly_df = results_df[results_df['is_anomaly'] == 'True']\n",
        "anomaly_df.to_csv('/content/drive/MyDrive/Colab Notebooks/system_anomalies.csv', index=False)\n",
        "print(f\"Saved {len(anomaly_df)} anomalies to a separate file\")\n",
        "\n",
        "# Save evaluation metrics to a text file\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/model_evaluation.txt', 'w') as f:\n",
        "    f.write(\"===== Autoencoder Evaluation Metrics =====\\n\")\n",
        "    f.write(f\"MAE: {mae:.6f}\\n\")\n",
        "    f.write(f\"MSE: {mse:.6f}\\n\")\n",
        "    f.write(f\"RMSE: {rmse:.6f}\\n\\n\")\n",
        "    f.write(\"===== Feature-wise Reconstruction Errors =====\\n\")\n",
        "    f.write(feature_metrics_sorted.to_string())\n",
        "    f.write(\"\\n\\nAnomaly threshold: {threshold}\\n\")\n",
        "    f.write(f\"Number of anomalies detected: {anomaly_count} ({anomaly_count/len(df)*100:.2f}%)\\n\")\n",
        "\n",
        "print(\"Evaluation metrics saved to Google Drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "1ek-seElU7Xg"
      },
      "outputs": [],
      "source": [
        "# Building on our existing autoencoder code\n",
        "# This would be implemented after the autoencoder section\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, RepeatVector, TimeDistributed, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from google.colab import drive\n",
        "import joblib\n",
        "import datetime\n",
        "import math\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define headers for the dataset\n",
        "header = [\n",
        "    \"timestamp\",\n",
        "    \"cpu_usage\",\n",
        "    \"top_1_cpu_proc_name\",\n",
        "    \"top_1_cpu_proc_usage\",\n",
        "    \"top_2_cpu_proc_name\",\n",
        "    \"top_2_cpu_proc_usage\",\n",
        "    \"top_3_cpu_proc_name\",\n",
        "    \"top_3_cpu_proc_usage\",\n",
        "    \"top_4_cpu_proc_name\",\n",
        "    \"top_4_cpu_proc_usage\",\n",
        "    \"top_5_cpu_proc_name\",\n",
        "    \"top_5_cpu_proc_usage\",\n",
        "    \"mem_usage\",\n",
        "    \"top_1_mem_proc_name\",\n",
        "    \"top_1_mem_proc_usage\",\n",
        "    \"top_2_mem_proc_name\",\n",
        "    \"top_2_mem_proc_usage\",\n",
        "    \"top_3_mem_proc_name\",\n",
        "    \"top_3_mem_proc_usage\",\n",
        "    \"top_4_mem_proc_name\",\n",
        "    \"top_4_mem_proc_usage\",\n",
        "    \"top_5_mem_proc_name\",\n",
        "    \"top_5_mem_proc_usage\",\n",
        "    \"nginx_active_connections\",\n",
        "    \"nginx_rps\"\n",
        "]\n",
        "\n",
        "# Load the dataset with semicolon delimiter\n",
        "df = pd.read_csv(\n",
        "    \"drive/MyDrive/Colab Notebooks/dataset/system_stats.csv\",\n",
        "    header=None,\n",
        "    names=header,\n",
        "    sep=';',\n",
        "    low_memory=False,\n",
        "    on_bad_lines='skip'\n",
        ")\n",
        "\n",
        "# Display basic information\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "df.head()\n",
        "\n",
        "# Handle timestamp parsing\n",
        "# First, clean up any extra characters that might interfere with parsing\n",
        "df['timestamp'] = df['timestamp'].str.replace('T', ' ')\n",
        "df['timestamp'] = df['timestamp'].str.split('.').str[0]\n",
        "\n",
        "# Now try to parse timestamps\n",
        "try:\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
        "except:\n",
        "    print(\"Warning: Some timestamp parsing failed, using a more flexible approach\")\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
        "\n",
        "# Drop rows with invalid timestamps\n",
        "df = df.dropna(subset=['timestamp'])\n",
        "print(f\"Dataset shape after cleaning timestamps: {df.shape}\")\n",
        "\n",
        "# Extract time features\n",
        "df['hour'] = df['timestamp'].dt.hour\n",
        "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "df['day_of_month'] = df['timestamp'].dt.day\n",
        "\n",
        "# Check data types and convert numerical columns from strings to float\n",
        "numeric_cols = [\n",
        "    'cpu_usage', 'top_1_cpu_proc_usage', 'top_2_cpu_proc_usage',\n",
        "    'top_3_cpu_proc_usage', 'top_4_cpu_proc_usage', 'top_5_cpu_proc_usage',\n",
        "    'mem_usage', 'top_1_mem_proc_usage', 'top_2_mem_proc_usage',\n",
        "    'top_3_mem_proc_usage', 'top_4_mem_proc_usage', 'top_5_mem_proc_usage',\n",
        "    'nginx_active_connections', 'nginx_rps'\n",
        "]\n",
        "\n",
        "for col in numeric_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Select only numerical features for the model (excluding process names)\n",
        "numerical_features = [\n",
        "    'cpu_usage', 'top_1_cpu_proc_usage', 'top_2_cpu_proc_usage',\n",
        "    'top_3_cpu_proc_usage', 'top_4_cpu_proc_usage', 'top_5_cpu_proc_usage',\n",
        "    'mem_usage', 'top_1_mem_proc_usage', 'top_2_mem_proc_usage',\n",
        "    'top_3_mem_proc_usage', 'top_4_mem_proc_usage', 'top_5_mem_proc_usage',\n",
        "    'nginx_active_connections', 'nginx_rps',\n",
        "    'hour', 'day_of_week', 'day_of_month'\n",
        "]\n",
        "\n",
        "# These are the features we'll use for training\n",
        "features = numerical_features.copy()\n",
        "\n",
        "# Check for and handle missing values\n",
        "print(f\"Missing values:\\n{df[features].isna().sum()}\")\n",
        "df[features] = df[features].fillna(0)\n",
        "\n",
        "# Assuming we already have labeled data from autoencoder or other source\n",
        "# If not, we need to generate labels for training\n",
        "# For this example, let's assume we have saved results from the autoencoder with labels\n",
        "try:\n",
        "    # Try to load previously saved results with anomaly labels\n",
        "    labeled_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/system_anomaly_full_results.csv')\n",
        "    print(\"Loaded labeled data from previous autoencoder results\")\n",
        "\n",
        "    # Convert \"True\"/\"False\" string labels to boolean\n",
        "    labeled_df['is_anomaly'] = labeled_df['is_anomaly'].map({'True': True, 'False': False})\n",
        "\n",
        "    # Ensure the timestamp is properly formatted\n",
        "    labeled_df['timestamp'] = pd.to_datetime(labeled_df['timestamp'])\n",
        "\n",
        "    # Sort by timestamp to ensure proper sequence\n",
        "    labeled_df = labeled_df.sort_values('timestamp')\n",
        "\n",
        "    # Use the labeled data for our analysis\n",
        "    df = labeled_df\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"No labeled data found. Using synthetic labels for demonstration.\")\n",
        "    # Create synthetic anomaly labels (5% anomaly rate) for demonstration\n",
        "    # In a real scenario, you would use actual labeled data or results from autoencoder\n",
        "    np.random.seed(42)\n",
        "    df['is_anomaly'] = np.random.choice([True, False], size=len(df), p=[0.05, 0.95])\n",
        "\n",
        "# Verify we have labels\n",
        "print(f\"Anomaly distribution: {df['is_anomaly'].value_counts(normalize=True)}\")\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "# Save the scaler for future use\n",
        "joblib.dump(scaler, '/content/drive/MyDrive/Colab Notebooks/feature_scaler.save')\n",
        "\n",
        "# Function to create sequences for LSTM\n",
        "def create_sequences(data, seq_length, target_col=None):\n",
        "    xs = []\n",
        "    ys = []\n",
        "\n",
        "    for i in range(len(data) - seq_length):\n",
        "        x = data.iloc[i:(i + seq_length)][features].values\n",
        "        xs.append(x)\n",
        "\n",
        "        if target_col is not None:\n",
        "            # For classification, use the label of the last point in the sequence\n",
        "            y = data.iloc[i + seq_length - 1][target_col]\n",
        "            ys.append(y)\n",
        "\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "# Set sequence length (window size)\n",
        "seq_length = 24  # For example, 24 data points\n",
        "\n",
        "# Create sequences for LSTM with target labels\n",
        "X_seq, y_seq = create_sequences(df, seq_length, 'is_anomaly')\n",
        "\n",
        "print(f\"Sequence data shape: {X_seq.shape}\")\n",
        "print(f\"Target labels shape: {y_seq.shape}\")\n",
        "print(f\"Anomaly rate in sequences: {np.mean(y_seq):.2%}\")\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_seq, y_seq, test_size=0.2, random_state=42, stratify=y_seq\n",
        ")\n",
        "\n",
        "print(f\"Training set shapes: X={X_train.shape}, y={y_train.shape}\")\n",
        "print(f\"Testing set shapes: X={X_test.shape}, y={y_test.shape}\")\n",
        "\n",
        "# Build LSTM Classification Model\n",
        "lstm_model = Sequential([\n",
        "    LSTM(64, activation='relu', input_shape=(seq_length, len(features)), return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "lstm_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Print model summary\n",
        "lstm_model.summary()\n",
        "\n",
        "# Set up callbacks\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/lstm_anomaly_model.h5',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = lstm_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopping, model_checkpoint],\n",
        "    class_weight={0: 1, 1: (1 - np.mean(y_train)) / np.mean(y_train)},  # Handle class imbalance\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('LSTM Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('LSTM Training Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Make predictions on test data\n",
        "y_pred_prob = lstm_model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# Display confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Normal', 'Anomaly'],\n",
        "            yticklabels=['Normal', 'Anomaly'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Display metrics\n",
        "print(\"\\n===== LSTM Classification Metrics =====\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Display detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Normal', 'Anomaly']))\n",
        "\n",
        "# Calculate metrics manually (as per the formulas provided)\n",
        "manual_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "manual_precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "manual_recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "manual_f1 = 2 * (manual_precision * manual_recall) / (manual_precision + manual_recall) if (manual_precision + manual_recall) > 0 else 0\n",
        "\n",
        "print(\"\\n===== Manually Calculated Metrics =====\")\n",
        "print(f\"TP: {tp}, TN: {tn}, FP: {fp}, FN: {fn}\")\n",
        "print(f\"Accuracy (TP+TN)/(TP+TN+FP+FN): {manual_accuracy:.4f}\")\n",
        "print(f\"Precision TP/(TP+FP): {manual_precision:.4f}\")\n",
        "print(f\"Recall TP/(TP+FN): {manual_recall:.4f}\")\n",
        "print(f\"F1-Score 2×(P×R)/(P+R): {manual_f1:.4f}\")\n",
        "\n",
        "# ROC Curve and AUC\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Save the model\n",
        "lstm_model.save('/content/drive/MyDrive/Colab Notebooks/lstm_anomaly_classifier.h5')\n",
        "print(\"LSTM model saved to Google Drive\")\n",
        "\n",
        "# Save evaluation metrics to a text file\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/lstm_evaluation.txt', 'w') as f:\n",
        "    f.write(\"===== LSTM Classification Metrics =====\\n\")\n",
        "    f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
        "    f.write(f\"Precision: {precision:.4f}\\n\")\n",
        "    f.write(f\"Recall: {recall:.4f}\\n\")\n",
        "    f.write(f\"F1-Score: {f1:.4f}\\n\\n\")\n",
        "    f.write(\"Confusion Matrix:\\n\")\n",
        "    f.write(f\"TP: {tp}, TN: {tn}, FP: {fp}, FN: {fn}\\n\\n\")\n",
        "    f.write(\"Classification Report:\\n\")\n",
        "    f.write(classification_report(y_test, y_pred, target_names=['Normal', 'Anomaly']))\n",
        "    f.write(f\"\\nROC AUC: {roc_auc:.4f}\\n\")\n",
        "\n",
        "print(\"Evaluation metrics saved to Google Drive\")\n",
        "\n",
        "# Function to detect anomalies in new data using the trained LSTM model\n",
        "def detect_lstm_anomalies(new_data, model, scaler, features, seq_length=24):\n",
        "    \"\"\"\n",
        "    Detect anomalies in new data using the trained LSTM model\n",
        "\n",
        "    Parameters:\n",
        "    - new_data: DataFrame with new system metrics\n",
        "    - model: Trained LSTM model\n",
        "    - scaler: Fitted MinMaxScaler\n",
        "    - features: List of feature names used in training\n",
        "    - seq_length: Sequence length used for training\n",
        "\n",
        "    Returns:\n",
        "    - DataFrame with anomaly predictions\n",
        "    \"\"\"\n",
        "    # Ensure data is sorted by timestamp\n",
        "    new_data = new_data.sort_values('timestamp')\n",
        "\n",
        "    # Scale the features\n",
        "    new_data[features] = scaler.transform(new_data[features])\n",
        "\n",
        "    # Create sequences\n",
        "    sequences = []\n",
        "    sequence_timestamps = []\n",
        "\n",
        "    # We need at least seq_length data points to make a prediction\n",
        "    if len(new_data) < seq_length:\n",
        "        print(\"Warning: Not enough data points for prediction\")\n",
        "        return new_data.copy()\n",
        "\n",
        "    for i in range(len(new_data) - seq_length + 1):\n",
        "        seq = new_data.iloc[i:i+seq_length][features].values\n",
        "        sequences.append(seq)\n",
        "        # The timestamp for the sequence is the timestamp of the last point\n",
        "        sequence_timestamps.append(new_data.iloc[i+seq_length-1]['timestamp'])\n",
        "\n",
        "    sequences = np.array(sequences)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions_prob = model.predict(sequences)\n",
        "    predictions = (predictions_prob > 0.5).astype(bool).flatten()\n",
        "\n",
        "    # Create result DataFrame with only the data points that have predictions\n",
        "    result_indices = new_data.index[seq_length-1:]\n",
        "    result = new_data.loc[result_indices].copy()\n",
        "\n",
        "    # Add prediction probability and binary prediction\n",
        "    result['lstm_anomaly_probability'] = predictions_prob\n",
        "    result['lstm_is_anomaly'] = predictions\n",
        "\n",
        "    return result\n",
        "\n",
        "# Example of how to use the function with new data\n",
        "print(\"\\nExample usage for real-time anomaly detection:\")\n",
        "print(\"model = load_model('/content/drive/MyDrive/Colab Notebooks/lstm_anomaly_classifier.h5')\")\n",
        "print(\"scaler = joblib.load('/content/drive/MyDrive/Colab Notebooks/feature_scaler.save')\")\n",
        "print(\"new_data = pd.read_csv('new_system_data.csv', sep=';', names=header)\")\n",
        "print(\"# Process new data (timestamp parsing, etc.)\")\n",
        "print(\"results = detect_lstm_anomalies(new_data, model, scaler, features)\")\n",
        "print(\"anomalies = results[results['lstm_is_anomaly']]\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AgIoPEuWM3Sa",
        "outputId": "6e3dd1e7-a29d-4d11-a64a-c092989c171d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}