{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, precision_recall_curve, auc, roc_curve\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import joblib\n",
    "import math\n",
    "import datetime\n",
    "import time\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define headers for the dataset\n",
    "header = [\n",
    "    \"timestamp\",\n",
    "    \"cpu_usage\",\n",
    "    \"top_1_cpu_proc_name\",\n",
    "    \"top_1_cpu_proc_usage\",\n",
    "    \"top_2_cpu_proc_name\",\n",
    "    \"top_2_cpu_proc_usage\",\n",
    "    \"top_3_cpu_proc_name\",\n",
    "    \"top_3_cpu_proc_usage\",\n",
    "    \"top_4_cpu_proc_name\",\n",
    "    \"top_4_cpu_proc_usage\",\n",
    "    \"top_5_cpu_proc_name\",\n",
    "    \"top_5_cpu_proc_usage\",\n",
    "    \"mem_usage\",\n",
    "    \"top_1_mem_proc_name\",\n",
    "    \"top_1_mem_proc_usage\",\n",
    "    \"top_2_mem_proc_name\",\n",
    "    \"top_2_mem_proc_usage\",\n",
    "    \"top_3_mem_proc_name\",\n",
    "    \"top_3_mem_proc_usage\",\n",
    "    \"top_4_mem_proc_name\",\n",
    "    \"top_4_mem_proc_usage\",\n",
    "    \"top_5_mem_proc_name\",\n",
    "    \"top_5_mem_proc_usage\",\n",
    "    \"nginx_active_connections\",\n",
    "    \"nginx_rps\"\n",
    "]\n",
    "\n",
    "# Load the dataset with semicolon delimiter\n",
    "df = pd.read_csv(\n",
    "    \"drive/MyDrive/Colab Notebooks/dataset/system_stats.csv\",\n",
    "    header=None,\n",
    "    names=header,\n",
    "    sep=';',\n",
    "    low_memory=False,\n",
    "    on_bad_lines='skip'\n",
    ")\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()\n",
    "\n",
    "# Handle timestamp parsing\n",
    "df['timestamp'] = df['timestamp'].str.replace('T', ' ')\n",
    "df['timestamp'] = df['timestamp'].str.split('.').str[0]\n",
    "\n",
    "try:\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "except:\n",
    "    print(\"Warning: Some timestamp parsing failed, using a more flexible approach\")\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "\n",
    "# Drop rows with invalid timestamps\n",
    "df = df.dropna(subset=['timestamp'])\n",
    "print(f\"Dataset shape after cleaning timestamps: {df.shape}\")\n",
    "\n",
    "# Convert numerical columns from strings to float\n",
    "numeric_cols = [\n",
    "    'cpu_usage', 'top_1_cpu_proc_usage', 'top_2_cpu_proc_usage',\n",
    "    'top_3_cpu_proc_usage', 'top_4_cpu_proc_usage', 'top_5_cpu_proc_usage',\n",
    "    'mem_usage', 'top_1_mem_proc_usage', 'top_2_mem_proc_usage',\n",
    "    'top_3_mem_proc_usage', 'top_4_mem_proc_usage', 'top_5_mem_proc_usage',\n",
    "    'nginx_active_connections', 'nginx_rps'\n",
    "]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Select only numerical features for the models\n",
    "numerical_features = [\n",
    "    'cpu_usage', 'top_1_cpu_proc_usage', 'top_2_cpu_proc_usage',\n",
    "    'top_3_cpu_proc_usage', 'top_4_cpu_proc_usage', 'top_5_cpu_proc_usage',\n",
    "    'mem_usage', 'top_1_mem_proc_usage', 'top_2_mem_proc_usage',\n",
    "    'top_3_mem_proc_usage', 'top_4_mem_proc_usage', 'top_5_mem_proc_usage',\n",
    "    'nginx_active_connections', 'nginx_rps'\n",
    "]\n",
    "\n",
    "# Check for and handle missing values\n",
    "print(f\"Missing values:\\n{df[numerical_features].isna().sum()}\")\n",
    "df[numerical_features] = df[numerical_features].fillna(0)\n",
    "\n",
    "# Normalize the data for the autoencoder\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(df[numerical_features]), \n",
    "    columns=numerical_features\n",
    ")\n",
    "\n",
    "# Save the scaler for future use\n",
    "joblib.dump(scaler, '/content/drive/MyDrive/Colab Notebooks/feature_scaler.pkl')\n",
    "\n",
    "# Split the data for autoencoder training\n",
    "X_train_ae, X_test_ae = train_test_split(df_scaled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# PART 1: AUTOENCODER\n",
    "#########################\n",
    "\n",
    "# Build the autoencoder model\n",
    "input_dim = X_train_ae.shape[1]\n",
    "\n",
    "# Define the encoder\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "# Encoder layers\n",
    "encoder = Dense(64, activation='relu')(input_layer)\n",
    "encoder = Dropout(0.2)(encoder)\n",
    "encoder = Dense(32, activation='relu')(encoder)\n",
    "encoder = Dropout(0.2)(encoder)\n",
    "\n",
    "# Bottleneck layer\n",
    "bottleneck = Dense(16, activation='relu')(encoder)\n",
    "\n",
    "# Decoder layers\n",
    "decoder = Dense(32, activation='relu')(bottleneck)\n",
    "decoder = Dropout(0.2)(decoder)\n",
    "decoder = Dense(64, activation='relu')(decoder)\n",
    "decoder = Dropout(0.2)(decoder)\n",
    "\n",
    "# Output layer\n",
    "output_layer = Dense(input_dim, activation='sigmoid')(decoder)\n",
    "\n",
    "# Create model\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Print model summary\n",
    "print(\"Autoencoder Model Summary:\")\n",
    "autoencoder.summary()\n",
    "\n",
    "# Train the autoencoder\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history_ae = autoencoder.fit(\n",
    "    X_train_ae, X_train_ae,\n",
    "    epochs=30,  # Reduced from 50 to make it run faster\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_ae, X_test_ae),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history_ae.history['loss'], label='Training Loss')\n",
    "plt.plot(history_ae.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Autoencoder Training History')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save the autoencoder model\n",
    "autoencoder.save('/content/drive/MyDrive/Colab Notebooks/system_autoencoder.h5')\n",
    "\n",
    "# Get reconstruction on the entire dataset\n",
    "reconstructed = autoencoder.predict(df_scaled)\n",
    "\n",
    "# Calculate reconstruction error (MSE per sample)\n",
    "mse = np.mean(np.power(df_scaled - reconstructed, 2), axis=1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "# MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(df_scaled, reconstructed)\n",
    "# MSE (Mean Squared Error)\n",
    "mse_overall = mean_squared_error(df_scaled, reconstructed)\n",
    "# RMSE (Root Mean Squared Error)\n",
    "rmse = math.sqrt(mse_overall)\n",
    "\n",
    "print(\"\\n===== Autoencoder Evaluation Metrics =====\")\n",
    "print(f\"MAE: {mae:.6f}\")\n",
    "print(f\"MSE: {mse_overall:.6f}\")\n",
    "print(f\"RMSE: {rmse:.6f}\")\n",
    "\n",
    "# Calculate per-feature reconstruction errors for analysis\n",
    "feature_mae = np.mean(np.abs(df_scaled.values - reconstructed), axis=0)\n",
    "feature_mse = np.mean(np.square(df_scaled.values - reconstructed), axis=0)\n",
    "feature_rmse = np.sqrt(feature_mse)\n",
    "\n",
    "# Create dataframe for feature-wise metrics\n",
    "feature_metrics = pd.DataFrame({\n",
    "    'Feature': numerical_features,\n",
    "    'MAE': feature_mae,\n",
    "    'MSE': feature_mse,\n",
    "    'RMSE': feature_rmse\n",
    "})\n",
    "\n",
    "# Sort by RMSE to see which features have the highest reconstruction error\n",
    "feature_metrics_sorted = feature_metrics.sort_values('RMSE', ascending=False)\n",
    "print(\"\\n===== Feature-wise Reconstruction Errors =====\")\n",
    "print(feature_metrics_sorted)\n",
    "\n",
    "# Visualize feature-wise reconstruction errors\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar(feature_metrics_sorted['Feature'], feature_metrics_sorted['RMSE'])\n",
    "plt.title('RMSE by Feature')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Add reconstruction error to original dataframe\n",
    "df['reconstruction_error'] = mse\n",
    "\n",
    "# Determine anomaly threshold (mean + 2*std)\n",
    "threshold = np.mean(mse) + 2 * np.std(mse)\n",
    "print(f\"Anomaly threshold: {threshold}\")\n",
    "\n",
    "# Flag anomalies\n",
    "df['is_anomaly'] = (df['reconstruction_error'] > threshold).astype(int)\n",
    "anomaly_count = df['is_anomaly'].sum()\n",
    "print(f\"Number of anomalies detected: {anomaly_count} ({anomaly_count/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Plot reconstruction error\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df.index, df['reconstruction_error'], label='Reconstruction Error')\n",
    "plt.axhline(y=threshold, color='r', linestyle='-', label=f'Threshold ({threshold:.4f})')\n",
    "plt.fill_between(df.index, threshold, df['reconstruction_error'],\n",
    "                 where=(df['reconstruction_error'] > threshold), color='red', alpha=0.3)\n",
    "plt.title('Reconstruction Error Over Time')\n",
    "plt.xlabel('Data Point Index')\n",
    "plt.ylabel('Reconstruction Error (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display anomalies with highest reconstruction error\n",
    "top_anomalies = df[df['is_anomaly'] == 1].sort_values('reconstruction_error', ascending=False).head(10)\n",
    "print(\"Top 10 anomalies by reconstruction error:\")\n",
    "display(top_anomalies[['timestamp', 'cpu_usage', 'mem_usage', 'nginx_rps', 'reconstruction_error']])\n",
    "\n",
    "# Feature contribution to anomalies\n",
    "if anomaly_count > 0:\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    anomaly_indices = df[df['is_anomaly'] == 1].index\n",
    "    feature_errors = np.power(df_scaled.iloc[anomaly_indices].values -\n",
    "                            reconstructed[anomaly_indices], 2)\n",
    "    feature_error_df = pd.DataFrame(feature_errors, columns=numerical_features)\n",
    "    feature_contribution = feature_error_df.mean().sort_values(ascending=False)\n",
    "\n",
    "    plt.bar(feature_contribution.index, feature_contribution.values)\n",
    "    plt.title('Feature Contribution to Anomalies')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Average Squared Error')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize normal vs anomalous data points for top contributing features\n",
    "if anomaly_count > 0:\n",
    "    top_features = feature_contribution.head(6).index\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, feature in enumerate(top_features):\n",
    "        ax = axes[i]\n",
    "        sns.histplot(data=df, x=feature, hue='is_anomaly', bins=30, ax=ax,\n",
    "                   palette={1: 'red', 0: 'blue'}, alpha=0.5, legend=i==0)\n",
    "        ax.set_title(f'Distribution of {feature}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize actual vs. reconstructed values for a few features\n",
    "sample_size = min(1000, len(df))  # Limit to 1000 samples for visualization\n",
    "sample_idx = np.random.choice(len(df), sample_size, replace=False)\n",
    "\n",
    "for feature in numerical_features[:3]:  # Visualize first 3 features\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Get original and reconstructed values\n",
    "    original = df_scaled.iloc[sample_idx][feature].values\n",
    "    reconstructed_values = reconstructed[sample_idx, numerical_features.index(feature)]\n",
    "\n",
    "    # Plot scatter of original vs reconstructed\n",
    "    plt.scatter(original, reconstructed_values, alpha=0.5)\n",
    "\n",
    "    # Plot perfect reconstruction line\n",
    "    min_val = min(original.min(), reconstructed_values.min())\n",
    "    max_val = max(original.max(), reconstructed_values.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "\n",
    "    plt.title(f'Original vs Reconstructed: {feature}')\n",
    "    plt.xlabel('Original Value (Normalized)')\n",
    "    plt.ylabel('Reconstructed Value')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Calculate error distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['reconstruction_error'], bins=50, kde=True)\n",
    "plt.axvline(threshold, color='r', linestyle='--', label=f'Threshold ({threshold:.4f})')\n",
    "plt.title('Distribution of Reconstruction Errors')\n",
    "plt.xlabel('Reconstruction Error (MSE)')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the labeled data\n",
    "df.to_csv('/content/drive/MyDrive/Colab Notebooks/system_data_with_anomalies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# PART 2: LSTM MODEL\n",
    "#########################\n",
    "\n",
    "# Define function to create sequences for LSTM\n",
    "def create_sequences(X, y, time_steps=10):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X.iloc[i:(i + time_steps)].values)\n",
    "        # Use the label of the last timestep in the sequence\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# Set sequence length \n",
    "TIME_STEPS = 10\n",
    "\n",
    "# Create sequences for LSTM\n",
    "X_seq, y_seq = create_sequences(df_scaled, df['is_anomaly'], TIME_STEPS)\n",
    "\n",
    "print(f\"Sequence data shape: X={X_seq.shape}, y={y_seq.shape}\")\n",
    "\n",
    "# Split the data for LSTM training\n",
    "train_size = int(len(X_seq) * 0.8)\n",
    "X_train, X_test = X_seq[:train_size], X_seq[train_size:]\n",
    "y_train, y_test = y_seq[:train_size], y_seq[train_size:]\n",
    "\n",
    "print(f\"Training data: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Testing data: X={X_test.shape}, y={y_test.shape}\")\n",
    "\n",
    "# Check class distribution\n",
    "print(f\"Training class distribution: {np.bincount(y_train.astype(int))}\")\n",
    "print(f\"Testing class distribution: {np.bincount(y_test.astype(int))}\")\n",
    "\n",
    "# Calculate class weights for imbalanced dataset\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "print(f\"Class weights: {class_weight_dict}\")\n",
    "\n",
    "# Build LSTM model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=(TIME_STEPS, len(numerical_features)), \n",
    "         return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Compile LSTM model\n",
    "lstm_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "print(\"LSTM Model Summary:\")\n",
    "lstm_model.summary()\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping_lstm = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint_lstm = ModelCheckpoint(\n",
    "    '/content/drive/MyDrive/Colab Notebooks/lstm_anomaly_detector.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the LSTM model\n",
    "history_lstm = lstm_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stopping_lstm, checkpoint_lstm],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# DETAILED LSTM VISUALIZATIONS\n",
    "#########################\n",
    "\n",
    "# 1. Plot LSTM training history - Loss and Accuracy\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_lstm.history['loss'], label='Training Loss')\n",
    "plt.plot(history_lstm.history['val_loss'], label='Validation Loss')\n",
    "plt.title('LSTM Training History - Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_lstm.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_lstm.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('LSTM Training History - Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate LSTM model on test set\n",
    "y_pred_proba = lstm_model.predict(X_test)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n===== LSTM Model Evaluation Metrics =====\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# 2. Plot confusion matrix with percentages\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# Create a heatmap for the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix (Counts)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks([0.5, 1.5], ['Normal (0)', 'Anomaly (1)'])\n",
    "plt.yticks([0.5, 1.5], ['Normal (0)', 'Anomaly (1)'])\n",
    "plt.show()\n",
    "\n",
    "# 3. Plot percentage confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_percent, annot=True, fmt='.1f', cmap='Blues', cbar=True, \n",
    "            cbar_kws={'label': 'Percentage (%)'})\n",
    "plt.title('Confusion Matrix (Percentages)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks([0.5, 1.5], ['Normal (0)', 'Anomaly (1)'])\n",
    "plt.yticks([0.5, 1.5], ['Normal (0)', 'Anomaly (1)'])\n",
    "plt.show()\n",
    "\n",
    "# 4. Plot ROC curve and calculate AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 5. Plot Precision-Recall curve\n",
    "precision_curve, recall_curve, thresholds_pr = precision_recall_curve(y_test, y_pred_proba)\n",
    "pr_auc = auc(recall_curve, precision_curve)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recall_curve, precision_curve, color='blue', lw=2, \n",
    "         label=f'PR curve (AUC = {pr_auc:.3f})')\n",
    "plt.axhline(y=sum(y_test)/len(y_test), color='navy', linestyle='--', \n",
    "            label=f'Baseline (Anomaly rate = {sum(y_test)/len(y_test):.3f})')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 6. Distribution of prediction probabilities\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(\n",
    "    y_pred_proba, \n",
    "    bins=50, \n",
    "    kde=True, \n",
    "    stat=\"density\", \n",
    "    color=\"blue\", \n",
    "    alpha=0.6\n",
    ")\n",
    "plt.axvline(x=0.5, color='r', linestyle='--', label='Threshold (0.5)')\n",
    "plt.title('Distribution of Prediction Probabilities')\n",
    "plt.xlabel('Predicted Probability of Anomaly')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 7. Distribution of prediction probabilities by actual class\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Get probabilities for each class\n",
    "normal_probs = y_pred_proba[y_test == 0]\n",
    "anomaly_probs = y_pred_proba[y_test == 1]\n",
    "\n",
    "sns.histplot(normal_probs, bins=30, alpha=0.5, color='blue', \n",
    "             label='Normal (Class 0)', kde=True)\n",
    "sns.histplot(anomaly_probs, bins=30, alpha=0.5, color='red', \n",
    "             label='Anomaly (Class 1)', kde=True)\n",
    "plt.axvline(x=0.5, color='black', linestyle='--', label='Threshold (0.5)')\n",
    "plt.title('Distribution of Prediction Probabilities by Actual Class')\n",
    "plt.xlabel('Predicted Probability of Anomaly')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 8. Threshold optimization plot - F1 Score\n",
    "# Calculate metrics for different thresholds\n",
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_t = (y_pred_proba > threshold).astype(int)\n",
    "    f1_scores.append(f1_score(y_test, y_pred_t))\n",
    "    precision_scores.append(precision_score(y_test, y_pred_t))\n",
    "    recall_scores.append(recall_score(y_test, y_pred_t))\n",
    "\n",
    "# Find best threshold for F1 score\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_f1 = f1_scores[best_idx]\n",
    "\n",
    "# Plot metrics vs thresholds\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(thresholds, f1_scores, 'b-', label='F1 Score')\n",
    "plt.plot(thresholds, precision_scores, 'g-', label='Precision')\n",
    "plt.plot(thresholds, recall_scores, 'r-', label='Recall')\n",
    "plt.axvline(x=best_threshold, color='k', linestyle='--', \n",
    "            label=f'Best Threshold = {best_threshold:.2f}, F1 = {best_f1:.3f}')\n",
    "plt.title('Model Performance Metrics vs. Classification Threshold')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Optimal threshold for F1 score: {best_threshold:.4f}, F1 score: {best_f1:.4f}\")\n",
    "\n",
    "# 9. Time series of actual vs predicted over sample periods\n",
    "sample_size = min(200, len(y_test))  # Show last 200 points or fewer if less available\n",
    "indices = np.arange(len(y_test) - sample_size, len(y_test))\n",
    "time_indices = np.arange(len(indices))\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(time_indices, y_test[indices], 'b-', label='Actual', alpha=0.7)\n",
    "plt.plot(time_indices, y_pred_proba[indices], 'r-', label='Predicted Probability', alpha=0.7)\n",
    "plt.axhline(y=0.5, color='g', linestyle='--', label='Threshold (0.5)')\n",
    "plt.fill_between(time_indices, 0, 1, \n",
    "                 where=(y_pred_proba[indices] > 0.5) & (y_test[indices] == 1),\n",
    "                 facecolor='lime', alpha=0.3, label='True Positive')\n",
    "plt.fill_between(time_indices, 0, 1, \n",
    "                 where=(y_pred_proba[indices] > 0.5) & (y_test[indices] == 0),\n",
    "                 facecolor='red', alpha=0.3, label='False Positive')\n",
    "plt.fill_between(time_indices, 0, 1, \n",
    "                 where=(y_pred_proba[indices] <= 0.5) & (y_test[indices] == 1),\n",
    "                 facecolor='orange', alpha=0.3, label='False Negative')\n",
    "plt.title('Time Series of Actual vs Predicted Anomalies')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Anomaly Score / Class')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 10. Analysis of model performance by feature\n",
    "test_data_indices = np.arange(train_size, train_size + len(X_test))\n",
    "test_df = df.iloc[test_data_indices].copy()\n",
    "test_df['predicted_proba'] = y_pred_proba\n",
    "test_df['predicted'] = y_pred\n",
    "\n",
    "# Feature impact on misclassifications\n",
    "def analyze_feature_impact():\n",
    "    # Get misclassifications\n",
    "    misclassified = test_df[test_df['is_anomaly'] != test_df['predicted']]\n",
    "    \n",
    "    # Get false positives and false negatives\n",
    "    fp = test_df[(test_df['is_anomaly'] == 0) & (test_df['predicted'] == 1)]\n",
    "    fn = test_df[(test_df['is_anomaly'] == 1) & (test_df['predicted'] == 0)]\n",
    "    \n",
    "    if len(fp) > 0 and len(fn) > 0:\n",
    "        # Compare feature values for misclassifications\n",
    "        fig, axes = plt.subplots(5, 3, figsize=(18, 25))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, feature in enumerate(numerical_features):\n",
    "            if i >= len(axes):\n",
    "                break\n",
    "                \n",
    "            ax = axes[i]\n",
    "            # Plot feature distribution by prediction result\n",
    "            sns.boxplot(x='predicted', y=feature, hue='is_anomaly', \n",
    "                       data=test_df, palette='Set3', ax=ax)\n",
    "            ax.set_title(f'Distribution of {feature}')\n",
    "            ax.set_xlabel('Predicted')\n",
    "            ax.set_ylabel(feature)\n",
    "            if i > 0:\n",
    "                ax.get_legend().remove()\n",
    "                \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot feature importance for misclassifications\n",
    "        feature_importance = {}\n",
    "        \n",
    "        # Calculate normalized mean difference between FP and normal, and FN and anomalies\n",
    "        for feature in numerical_features:\n",
    "            # For false positives: how different from normal data?\n",
    "            normal_mean = test_df[test_df['is_anomaly'] == 0][feature].mean()\n",
    "            normal_std = test_df[test_df['is_anomaly'] == 0][feature].std()\n",
    "            \n",
    "            fp_diff = abs(fp[feature].mean() - normal_mean) / max(1e-10, normal_std)\n",
    "            \n",
    "            # For false negatives: how different from anomalous data?\n",
    "            anomaly_mean = test_df[test_df['is_anomaly'] == 1][feature].mean()\n",
    "            anomaly_std = test_df[test_df['is_anomaly'] == 1][feature].std()\n",
    "            \n",
    "            fn_diff = abs(fn[feature].mean() - anomaly_mean) / max(1e-10, anomaly_std)\n",
    "            \n",
    "            # Overall importance: average of both\n",
    "            feature_importance[feature] = (fp_diff + fn_diff) / 2\n",
    "        \n",
    "        # Plot feature importance\n",
    "        importance_df = pd.DataFrame.from_dict(feature_importance, orient='index', \n",
    "                                               columns=['Importance'])\n",
    "        importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x=importance_df.index, y='Importance', data=importance_df)\n",
    "        plt.title('Feature Importance for Misclassifications')\n",
    "        plt.xlabel('Features')\n",
    "        plt.ylabel('Importance Score (Normalized Difference)')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Run feature impact analysis\n",
    "analyze_feature_impact()\n",
    "\n",
    "# Save evaluation metrics to file\n",
    "with open('/content/drive/MyDrive/Colab Notebooks/lstm_model_evaluation.txt', 'w') as f:\n",
    "    f.write(\"===== LSTM Model Evaluation Metrics =====\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.4f}\\n\")\n",
    "    f.write(f\"F1-Score: {f1:.4f}\\n\")\n",
    "    f.write(f\"ROC AUC: {roc_auc:.4f}\\n\")\n",
    "    f.write(f\"PR AUC: {pr_auc:.4f}\\n\")\n",
    "    f.write(f\"Optimal threshold for F1: {best_threshold:.4f}\\n\")\n",
    "    f.write(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "\n",
    "print(\"Evaluation metrics saved to Google Drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# PART 3: REAL-TIME DETECTION\n",
    "#########################\n",
    "\n",
    "def detect_anomalies_realtime(new_data, lstm_model, scaler, time_steps=10):\n",
    "    \"\"\"\n",
    "    Detect anomalies in new data in real-time\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    new_data : pandas DataFrame \n",
    "        New data points to check for anomalies (must have all needed numerical features)\n",
    "    lstm_model : Keras model\n",
    "        Trained LSTM model\n",
    "    scaler : MinMaxScaler\n",
    "        Fitted scaler to normalize data\n",
    "    time_steps : int\n",
    "        Number of time steps used in LSTM training\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Dictionary with anomaly predictions and probabilities\n",
    "    \"\"\"\n",
    "    # Ensure we have the required features\n",
    "    required_features = numerical_features\n",
    "    missing_features = [f for f in required_features if f not in new_data.columns]\n",
    "    \n",
    "    if missing_features:\n",
    "        return {\n",
    "            \"error\": f\"Missing required features: {missing_features}\",\n",
    "            \"timestamp\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "    \n",
    "    # Handle missing values\n",
    "    data = new_data[required_features].fillna(0).copy()\n",
    "    \n",
    "    # Scale the data\n",
    "    data_scaled = scaler.transform(data)\n",
    "    \n",
    "    # If we have at least time_steps points, we can make a prediction\n",
    "    if len(data) >= time_steps:\n",
    "        # Get the most recent time_steps points\n",
    "        recent_data = data_scaled[-time_steps:]\n",
    "        \n",
    "        # Reshape for LSTM input format [samples, time_steps, features]\n",
    "        X_new = recent_data.reshape(1, time_steps, len(required_features))\n",
    "        \n",
    "        # Make prediction\n",
    "        anomaly_prob = lstm_model.predict(X_new)[0][0]\n",
    "        \n",
    "        # Use optimal threshold if available, otherwise default to 0.5\n",
    "        threshold = best_threshold if 'best_threshold' in locals() else 0.5\n",
    "        is_anomaly = bool(anomaly_prob > threshold)\n",
    "        \n",
    "        return {\n",
    "            \"is_anomaly\": is_anomaly,\n",
    "            \"anomaly_probability\": float(anomaly_prob),\n",
    "            \"threshold\": float(threshold),\n",
    "            \"timestamp\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"error\": \"Not enough data points\",\n",
    "            \"required\": time_steps,\n",
    "            \"provided\": len(data),\n",
    "            \"timestamp\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "\n",
    "# Example of using the real-time detection function\n",
    "def simulation_example():\n",
    "    # For demonstration: get some sample points from test data\n",
    "    sample_history = df.iloc[-20:-10][numerical_features].reset_index(drop=True)\n",
    "    \n",
    "    # Simulate a new normal data point\n",
    "    new_normal_point = df.iloc[-9:-8][numerical_features].copy()\n",
    "    \n",
    "    # Simulate an anomalous data point (high CPU usage)\n",
    "    new_anomaly_point = df.iloc[-9:-8][numerical_features].copy()\n",
    "    new_anomaly_point['cpu_usage'] = new_anomaly_point['cpu_usage'] * 3\n",
    "    \n",
    "    # Combine history with new point\n",
    "    data_with_normal = pd.concat([sample_history, new_normal_point]).reset_index(drop=True)\n",
    "    data_with_anomaly = pd.concat([sample_history, new_anomaly_point]).reset_index(drop=True)\n",
    "    \n",
    "    # Make predictions\n",
    "    result_normal = detect_anomalies_realtime(data_with_normal, lstm_model, scaler, TIME_STEPS)\n",
    "    result_anomaly = detect_anomalies_realtime(data_with_anomaly, lstm_model, scaler, TIME_STEPS)\n",
    "    \n",
    "    print(\"\\n===== Real-time Detection Example =====\")\n",
    "    print(\"Normal data point result:\", result_normal)\n",
    "    print(\"Anomalous data point result:\", result_anomaly)\n",
    "\n",
    "# Run the simulation example\n",
    "simulation_example()\n",
    "\n",
    "# Function to simulate real-time monitoring\n",
    "def setup_realtime_monitoring():\n",
    "    \"\"\"Simulate real-time monitoring with a buffer of recent data points\"\"\"\n",
    "    \n",
    "    # Start with a buffer of historical data (last TIME_STEPS points)\n",
    "    buffer = df.iloc[-30:-20][numerical_features].reset_index(drop=True)\n",
    "    print(f\"Starting with buffer of {len(buffer)} historical data points\")\n",
    "    \n",
    "    # Initialize arrays to store results for visualization\n",
    "    timestamps = []\n",
    "    probabilities = []\n",
    "    anomaly_status = []\n",
    "    threshold_values = []\n",
    "    \n",
    "    # Simulate 10 new incoming data points\n",
    "    for i in range(10):\n",
    "        print(f\"\\n--- Iteration {i+1} ---\")\n",
    "        \n",
    "        # Simulate new data point (make some anomalous)\n",
    "        if i % 3 == 0:  # Every 3rd point is anomalous\n",
    "            new_point = df.iloc[-15+i:1-14+i][numerical_features].copy()\n",
    "            new_point['cpu_usage'] = new_point['cpu_usage'] * 2  # Make it anomalous\n",
    "            print(\"Created anomalous data point (high CPU)\")\n",
    "        else:\n",
    "            new_point = df.iloc[-15+i:1-14+i][numerical_features].copy()\n",
    "            print(\"Created normal data point\")\n",
    "        \n",
    "        # Add to buffer\n",
    "        buffer = pd.concat([buffer, new_point]).reset_index(drop=True)\n",
    "        \n",
    "        # Keep only the most recent TIME_STEPS points\n",
    "        if len(buffer) > TIME_STEPS:\n",
    "            buffer = buffer.iloc[-TIME_STEPS:].reset_index(drop=True)\n",
    "        \n",
    "        # Detect anomalies\n",
    "        result = detect_anomalies_realtime(buffer, lstm_model, scaler, TIME_STEPS)\n",
    "        \n",
    "        # Store results for visualization\n",
    "        timestamps.append(str(i+1))\n",
    "        \n",
    "        # Print result\n",
    "        if \"error\" in result:\n",
    "            print(f\"Error: {result['error']}\")\n",
    "            probabilities.append(0)\n",
    "            anomaly_status.append(\"Error\")\n",
    "            threshold_values.append(0.5)\n",
    "        else:\n",
    "            probabilities.append(result[\"anomaly_probability\"])\n",
    "            anomaly_status.append(\"Anomaly\" if result[\"is_anomaly\"] else \"Normal\")\n",
    "            threshold_values.append(result[\"threshold\"])\n",
    "            \n",
    "            if result[\"is_anomaly\"]:\n",
    "                print(f\"ALERT! Anomaly detected with probability {result['anomaly_probability']:.4f}\")\n",
    "            else:\n",
    "                print(f\"Normal data (probability of anomaly: {result['anomaly_probability']:.4f})\")\n",
    "        \n",
    "        # In a real system, you would wait 15 seconds here\n",
    "        time.sleep(1)  # For simulation, we just wait 1 second\n",
    "    \n",
    "    print(\"\\nReal-time monitoring simulation complete\")\n",
    "    \n",
    "    # Visualize results\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Plot anomaly probabilities\n",
    "    plt.plot(timestamps, probabilities, 'b-o', label='Anomaly Probability')\n",
    "    \n",
    "    # Plot threshold\n",
    "    plt.plot(timestamps, threshold_values, 'r--', label='Threshold')\n",
    "    \n",
    "    # Highlight anomalies\n",
    "    for i, status in enumerate(anomaly_status):\n",
    "        if status == \"Anomaly\":\n",
    "            plt.scatter(timestamps[i], probabilities[i], color='red', s=100, zorder=5, \n",
    "                       label='_' if i > 0 else 'Detected Anomaly')\n",
    "    \n",
    "    # Add annotations\n",
    "    for i, prob in enumerate(probabilities):\n",
    "        plt.annotate(f'{prob:.3f}', (timestamps[i], prob + 0.02), \n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.title('Real-time Anomaly Detection Simulation')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Anomaly Probability')\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Run the real-time monitoring simulation with visualization\n",
    "setup_realtime_monitoring()\n",
    "\n",
    "# Example function to load models and detect anomalies\n",
    "def load_models_and_detect(new_data_csv):\n",
    "    \"\"\"\n",
    "    Load saved models and detect anomalies in new data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    new_data_csv : str\n",
    "        Path to CSV with new data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with anomaly predictions\n",
    "    \"\"\"\n",
    "    # Load models and scaler\n",
    "    lstm_model = load_model('/content/drive/MyDrive/Colab Notebooks/lstm_anomaly_detector.h5')\n",
    "    scaler = joblib.load('/content/drive/MyDrive/Colab Notebooks/feature_scaler.pkl')\n",
    "    \n",
    "    # Load new data\n",
    "    new_data = pd.read_csv(new_data_csv)\n",
    "    \n",
    "    # Detect anomalies\n",
    "    result = detect_anomalies_realtime(new_data, lstm_model, scaler, TIME_STEPS)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Usage example (commented out)\n",
    "\"\"\"\n",
    "# How to use in production:\n",
    "result = load_models_and_detect('path_to_new_data.csv')\n",
    "if result.get('is_anomaly', False):\n",
    "    # Send alert or take action\n",
    "    print(f\"ALERT: Anomaly detected! Probability: {result['anomaly_probability']}\")\n",
    "else:\n",
    "    print(\"System operating normally\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nModel training, visualization, and evaluation complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
